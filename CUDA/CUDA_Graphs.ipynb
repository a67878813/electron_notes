{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA 可用streams 或Graph工作。\n",
    "\n",
    "stream 为有向无环图。\n",
    "\n",
    "graph node is any **asynchronous** CUDA operation.\n",
    "\n",
    "Graph is sequence of *operations*, connected by *dependencies*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations are one of:\n",
    "    Kernel Launch\n",
    "    CPU Function Call\n",
    "    Memcopy/Memset\n",
    "    Memory Alloc/Free\n",
    "    Sub-Graph\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好处：\n",
    "节省小且多的stream启动开销（microseconds）；节省cpu 。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA graph has Three-stage execution model\n",
    "\n",
    "Define:\n",
    "    Single Graph \"Template\".\n",
    "\n",
    "    Created in host code, or loaded from disk,\n",
    "    or built up from libraries.\n",
    "\n",
    "Instantiate:\n",
    "    Multiple \"Executable Graphs\"\n",
    "\n",
    "    Snapshot of template .\n",
    "    Sets up & initializes GPU execution structures.\n",
    "    (create once, run many times )\n",
    "\n",
    "Execute:\n",
    "    Running in CUDA Streams.\n",
    "    Concurrency in graph *is not* limited by stream\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying Graphs in-place\n",
    "\n",
    "Stream Launch:\n",
    "\n",
    "Graph Update:\n",
    "\n",
    "Graph Re-launch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 ways to create CUDA graphs\n",
    "\n",
    "1. Stream Capture\n",
    "\n",
    "    Records operations without actually launching a kernel\n",
    "\n",
    "    Library must call an API to tell if kernels are being captured instead of launched.\n",
    "    #### Capture operation falls\n",
    "    . Problem if libray calls cudaStreamSynchronize() or any other synchronous operation.\n",
    "    . Capture is not launching anything so synchronize cannot wait for anything.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudaStreamBeginCapture(&stream1);\n",
    "\n",
    "//build stream work as usual \n",
    "A<<< ..., stream1>>>();\n",
    "cudaEventRecord(e1,stream1);\n",
    "B \n",
    "C \n",
    "cudaEventRecord(e1,stream1);\n",
    "\n",
    "cudaStreamWaitEvent(stream1,e2);\n",
    "D \n",
    "\n",
    "//convert the stream to a graph\n",
    "cudaStreamEndCapture(stream1,&graph);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create Graphs Directly\n",
    "    map Graph-Based Workflows Directly Into CUDA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudaGraphCreate(&graph);\n",
    "cudaGraphAddNode(graph,kernel_a,{},...);\n",
    "cudaGraphAddNode(graph,kernel_b,{kernel_a},...);\n",
    "\n",
    "...\n",
    "\n",
    "//Instantiate graph and apply optimizations\n",
    "cudaGraphInstantiate(&instance, graph);\n",
    "\n",
    "//Launch executable graph 100 times\n",
    "for(int i=0;i<100;++i){\n",
    "    cudaGraphLaunch(instance, stream);}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Execution Semantics\n",
    "\n",
    "    Order graph work with other non-graph CUDA work\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launchWork(cudaGraphExec_t i1, cudaGraphExec_t i2,\n",
    "    CPU_FUNC cpu, cudaStream_t stream){\n",
    "\n",
    "        A<<<256,256,0,stream>>>(); //kernel launch\n",
    "        cudaGraphLaunch(i1,stream); //Graph launch\n",
    "        cudaStreamAddCallback(stream,cpu);//CPU callback \n",
    "        cudaGraphLaunch(i2,stream); //Graph launch\n",
    "\n",
    "        cudaStreamSynchronize(stream);\n",
    "\n",
    "\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs ignore stream serialization rull\n",
    "\n",
    "Launch Stream is Used *only* for ordering with other work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph is not automatic placement \n",
    "\n",
    "User must define Execution location for each *NODE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution dependencies\n",
    "\n",
    "Data dependency graph definition\n",
    "\n",
    "Task Input Outpus\n",
    "A nont X  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudaGraphAddNode(graph,A,{},...);\n",
    "\n",
    "cudaGraphAddNode(graph,B,{A},...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ALL* **data dependencies** can trivially be mapped to **execution dependencies**, but\n",
    "*NOT ALL* **execution dependencies** can be mapped to **data dependencies**.\n",
    "\n",
    "\n",
    "**execution dependencies** is super sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What Graph can do\n",
    "\n",
    "Rapid re_issue of work\n",
    "\n",
    "for(int i=0;i<5;i++){\n",
    "    launch_graph(G);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
