{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "性能计数  异步调用 0_Introduction\\asyncAPI\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常见流程\n",
    "\n",
    "//可选性能计数\n",
    "在host准备数据\n",
    "\n",
    "alloc Device memory\n",
    "\n",
    "copy to Device_memory from host\n",
    "\n",
    "run device_kernels 1 2 3\n",
    "\n",
    "copy to host_memory from device\n",
    "\n",
    "check value\n",
    "\n",
    "释放device资源 cudaFree(ptr)\n",
    "\n",
    "必要时释放host资源\n",
    "//可选性能计数\n",
    "\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernel 例子\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "// Kernels\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "//! Transforms vector.\n",
    "//! Applies the __device__ function \"f\" to each element of the vector \"v\".\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "__global__ void transformVector(float *v, deviceFunc f, uint size) {\n",
    "  uint tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "  if (tid < size) {\n",
    "    v[tid] = (*f)(v[tid]);\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "静态device fun ptr例子\n",
    "typedef float (*deviceFunc)(float);\n",
    "\n",
    "\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "// Static device pointers to __device__ functions.\n",
    "__device__ deviceFunc dMultiplyByTwoPtr = multiplyByTwo;\n",
    "__device__ deviceFunc dDivideByTwoPtr = divideByTwo;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查找device函数\n",
    "    // This will pick the best possible CUDA capable device.\n",
    "    findCudaDevice(argc, (const char **)argv);\n",
    "\n",
    "\n",
    "\n",
    "// Create and populate device vector.\n",
    "float *dVector;\n",
    "cout << \"devide &dVector = \" << &dVector << '\\n';\n",
    "checkCudaErrors(cudaMalloc(&dVector设备内存指针, kVectorSize * sizeof(float))内存大小);\n",
    "\n",
    "\n",
    "    checkCudaErrors(cudaMemcpy(dVector设备指针, &hVector[0]主机指针,\n",
    "                               kVectorSize * sizeof(float) 大小,\n",
    "                               cudaMemcpyHostToDevice 方向));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拷贝device函数指针\n",
    "\n",
    "    // Test library functions.\n",
    "    deviceFunc hFunctionPtr;\n",
    "\n",
    "    // on device for every &dVector , *2  \n",
    "    cudaMemcpyFromSymbol(&hFunctionPtr目标, dMultiplyByTwoPtr源, sizeof(deviceFunc)大小);\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行kernel\n",
    " 检查错误\n",
    "\n",
    "    transformVector<<<dimGrid, dimBlock>>>(dVector, hFunctionPtr, kVectorSize);\n",
    "    checkCudaErrors(cudaGetLastError());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim1\n",
    "\n",
    "kernel序号\n",
    "\n",
    "int i = blockDim.x*blockIdex.x + threadIdx.x;\n",
    "1维kernel编号， = block含thread数   * block序号 + thread序号"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
